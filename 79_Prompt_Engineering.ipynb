{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhuYHP+TJf3cXrvkybEG+G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JhonnyLimachi/Sigmoidal/blob/main/79_Prompt_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img alt=\"Colaboratory logo\" width=\"15%\" src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/novo_logo_bg_claro.png\">\n",
        "\n",
        "# Prompt Engineering\n",
        "\n",
        "Bem-vindo ao curso **Prompt Engineering**! Neste curso, você mergulhará na arte da engenharia de prompts, uma habilidade essencial para aprimorar o uso de modelos de linguagem avançados, como o GPT-3.5, em suas tarefas de ciência de dados.\n",
        "\n",
        "<center><img src=\"https://i.guim.co.uk/img/media/6bc60b720f2288e8b8153dc04e8b079b4a7a9dd6/0_93_4276_2566/master/4276.jpg?width=465&dpr=1&s=none\" height=\"300px\"></center>\n",
        "\n",
        "\n",
        "A engenharia de prompts envolve a criação estratégica de instruções ou sugestões de entrada para modelos de linguagem, visando obter resultados mais precisos e relevantes. Você aprenderá a ajustar os prompts para se alinhar melhor aos seus objetivos, explorando técnicas como o uso de tokens especiais, controle de temperatura e contextualização para gerar saídas mais personalizadas.\n",
        "\n",
        "Durante o curso, abordaremos exemplos práticos, estudos de caso e exercícios hands-on que simulam situações do cotidiano de um cientista de dados. Ao final, você estará pronto para aplicar efetivamente a engenharia de prompts em seus projetos, elevando a qualidade e relevância das respostas geradas por modelos de linguagem avançados.\n",
        "\n",
        "Prepare-se para dominar a habilidade de engenharia de prompts e elevar suas capacidades como cientista de dados. Vamos começar esta jornada de aprendizado transformadora!\n",
        "\n",
        "Ao longo deste curso, usaremos o modelo `gpt-3.5-turbo`, e o endpoint Chat Completions.\n"
      ],
      "metadata": {
        "id": "NJelASxfqQ8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 01 - Outline\n",
        "## Large Language Models\n",
        "\n",
        "`Large Language Models` (LLMs), ou Modelos de Linguagem de Grande Escala, são uma classe de modelos de inteligência artificial (IA) projetados para entender e gerar linguagem humana de maneira avançada. Esses modelos são treinados em enormes conjuntos de dados textuais para aprender padrões linguísticos, estruturas gramaticais, relações semânticas e até mesmo conhecimento factual sobre o mundo.\n",
        "\n",
        "Os LLMs são alimentados por redes neurais profundas, especificamente modelos de atenção, que permitem que eles compreendam o contexto e as relações entre palavras e frases em um texto. Isso lhes confere a capacidade de realizar uma variedade de tarefas relacionadas à linguagem natural, como:\n",
        "\n",
        "* Geração de Texto: Os LLMs podem criar textos coesos, que variam desde parágrafos explicativos até histórias completas, com base em um prompt ou contexto inicial.\n",
        "\n",
        "* Tradução: Eles podem traduzir texto de uma língua para outra, mantendo o significado e a fluência.\n",
        "\n",
        "* Resposta a Perguntas: LLMs podem responder perguntas formuladas em linguagem natural, com base em informações contidas nos dados de treinamento.\n",
        "\n",
        "* Sumarização Automática: Eles podem criar resumos concisos de textos longos, capturando os pontos principais.\n",
        "\n",
        "* Classificação de Texto: LLMs podem classificar textos em categorias pré-definidas, como análise de sentimento, detecção de spam, etc.\n",
        "\n",
        "* Geração de Código: Alguns LLMs são capazes de gerar código de programação com base em descrições em linguagem natural.\n",
        "\n",
        "* Assistência a Escrita: Eles podem sugerir palavras, frases ou até mesmo completar parágrafos para auxiliar na redação.\n",
        "\n",
        "* Diálogo e Interação: LLMs podem manter conversas coerentes e contextualizadas, proporcionando interações mais naturais.\n",
        "\n",
        "LLMs têm evoluído consideravelmente em tamanho e capacidade ao longo dos anos. Modelos como GPT-3 têm trilhões de parâmetros, o que lhes permite lidar com tarefas complexas e gerar saídas que frequentemente se assemelham ao estilo humano de comunicação. Esses modelos têm uma ampla gama de aplicações em pesquisa, negócios, educação e muito mais, revolucionando a maneira como a IA interage com e compreende a linguagem humana."
      ],
      "metadata": {
        "id": "LiiXYRrfqXye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tipos de Large Language Models\n",
        "\n",
        "`Base LLM (Large Language Model)`\n",
        "\n",
        "Um Base LLM, ou Modelo de Linguagem de Base, é um modelo de inteligência artificial que aprende a linguagem humana a partir de enormes quantidades de texto. Ele pode responder a perguntas, gerar texto e realizar várias tarefas relacionadas à linguagem com base no que aprendeu. No entanto, ele precisa de um prompt (uma instrução ou pergunta) para entender o que você deseja que ele faça.\n",
        "\n",
        "`Instruction Tuned LLM (Large Language Model com Ajuste de Instrução)`\n",
        "\n",
        "Um Instruction Tuned LLM, ou Modelo de Linguagem de Grande Escala com Ajuste de Instrução, é um tipo de LLM que pode ser direcionado com instruções específicas. Isso significa que, além do prompt, você pode incluir instruções detalhadas para orientar o modelo em direção às respostas desejadas. Isso torna o modelo mais preciso e alinhado com o que você precisa.\n",
        "\n",
        "Em resumo, a diferença entre um Base LLM e um Instruction Tuned LLM está na capacidade de fornecer instruções detalhadas para o último, permitindo maior controle sobre suas respostas. Enquanto o Base LLM precisa de prompts genéricos, o Instruction Tuned LLM responde melhor a instruções específicas, tornando-o mais eficaz para tarefas específicas e resultados mais direcionados.\n",
        "\n",
        "Neste curso, vamos focar em `Instruction Tuned LLMs`, como o Chat GPT."
      ],
      "metadata": {
        "id": "HS-fZ45Zu1lc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdO7TgSrqECc",
        "outputId": "1997211f-50aa-4554-9073-2ed08c3ff675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai -q"
      ]
    }
  ]
}